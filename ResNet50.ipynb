{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50 from Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to import used libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, matplotlib.pyplot as plt, numpy as np, os\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam\n",
    "from helper.prepare_data import prepare_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we pick the dataset that we would like to use from:\n",
    "<br>1 - Age, gender, ethnicity CSV\n",
    "<br>2 - UTKFace\n",
    "<br>3 - Fairface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = 2\n",
    "colour = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data from each dataset so that we end up with normalized pixels and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y_age, y_gender, y_ethnicity, img_size = prepare_data(choice = choice, colour = colour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display some exemplary images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the whole grid of images\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# display first 25 images in a 5x5 grid\n",
    "for i in range(0, 25):\n",
    "    plt.subplot(5, 5, (i % 25) + 1)\n",
    "    plt.grid(False)\n",
    "    #disable x and y axis description\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if colour:\n",
    "        plt.imshow(x[i].reshape(img_size, img_size, 3), cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(x[i].reshape(img_size, img_size), cmap='gray')\n",
    "    # A = age, G = gender, E = ethnicity\n",
    "    plt.xlabel(\"A: \"+ str(y_age[i]) + \" G: \" + str(y_gender[i]) + (\" E: \" + str(y_ethnicity[i]) if y_ethnicity.size > 0 else \"\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNet implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet50(input_shape = (img_size, img_size, 3), include_top = False, weights = 'imagenet')\n",
    "base_model.trainable = False\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "gender_prediction_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "age_prediction_layer = tf.keras.layers.Dense(1, activation = 'relu')\n",
    "\n",
    "model_gender = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  gender_prediction_layer\n",
    "])\n",
    "\n",
    "model_gender.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate = 0.001), loss = 'binary_crossentropy', metrics = ['accuracy', 'mae'])\n",
    "model_gender.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_age = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  age_prediction_layer\n",
    "])\n",
    "\n",
    "model_age.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate = 0.001), loss = 'mae', metrics = ['accuracy', 'mae'])\n",
    "model_age.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_age, to_file = os.getcwd() + '//images//models//resnet50_model.png', show_shapes = True, show_dtype = False, show_layer_names = False, rankdir = 'TB', expand_nested = False, dpi = 96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the age model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_age = model_age.fit(x, y_age, epochs = 20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_acc = history_age.history['mae']\n",
    "age_val_acc = history_age.history['val_mae']\n",
    "epochs = range(len(age_acc))\n",
    "\n",
    "plt.plot(epochs, age_acc, 'b', label='Training Mean Absolute Error')\n",
    "plt.plot(epochs, age_val_acc, 'r', label='Validation Mean Absolute Error')\n",
    "plt.title('Age Mean Absolute Error Graph')\n",
    "plt.xticks(np.arange(min(epochs), max(epochs)+2, 2.0))\n",
    "plt.legend()\n",
    "plt.savefig(os.getcwd() + '//images//plots//resnet50_age_mae_ds_' + str(choice), bbox_inches='tight')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_acc = history_age.history['accuracy']\n",
    "age_val_acc = history_age.history['val_accuracy']\n",
    "epochs = range(len(age_acc))\n",
    "\n",
    "plt.plot(epochs, age_acc, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, age_val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Age Accuracy Graph')\n",
    "plt.xticks(np.arange(min(epochs), max(epochs)+2, 2.0))\n",
    "plt.legend()\n",
    "plt.savefig(os.getcwd() + '//images//plots//resnet50_age_accuracy_ds_' + str(choice))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the gender model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_gender = model_gender.fit(x, y_gender, epochs = 20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_acc = history_gender.history['mae']\n",
    "gender_val_acc = history_gender.history['val_mae']\n",
    "epochs = range(len(gender_acc))\n",
    "\n",
    "plt.plot(epochs, gender_acc, 'b', label='Training Mean Absolute Error')\n",
    "plt.plot(epochs, gender_val_acc, 'r', label='Validation Mean Absolute Error')\n",
    "plt.title('Gender Mean Absolute Error Graph')\n",
    "plt.xticks(np.arange(min(epochs), max(epochs)+2, 2.0))\n",
    "plt.legend()\n",
    "plt.savefig(os.getcwd() + '//images//plots//resnet50_gender_mae_ds_' + str(choice), bbox_inches='tight')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_acc = history_gender.history['accuracy']\n",
    "gender_val_acc = history_gender.history['val_accuracy']\n",
    "epochs = range(len(gender_acc))\n",
    "\n",
    "plt.plot(epochs, gender_acc, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, gender_val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Gender Accuracy Graph')\n",
    "plt.xticks(np.arange(min(epochs), max(epochs)+2, 2.0))\n",
    "plt.legend()\n",
    "plt.savefig(os.getcwd() + '//images//plots//resnet50_gender_accuracy_ds_' + str(choice))\n",
    "plt.figure()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
