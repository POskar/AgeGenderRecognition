{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we will work with UTKFace database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, pandas as pd, matplotlib.pyplot as plt, numpy as np, os\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input\n",
    "from keras.utils import load_img, plot_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the images from UTKFace folder and store information about path, age and gender in lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.getcwd() + '/UTKFace/'\n",
    "\n",
    "# labels - age, gender, ethnicity\n",
    "image_paths = []\n",
    "age_labels = []\n",
    "gender_labels = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    image_path = os.path.join(directory, filename)\n",
    "    temp = filename.split('_')\n",
    "    age = int(temp[0])\n",
    "    gender = int(temp[1])\n",
    "    image_paths.append(image_path)\n",
    "    age_labels.append(age)\n",
    "    gender_labels.append(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "df = pd.DataFrame()\n",
    "df['image'], df['age'], df['gender'] = image_paths, age_labels, gender_labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display some exemplary images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the whole grid of images\n",
    "plt.figure(figsize=(10, 10))\n",
    "files = df.iloc[0:25]\n",
    "\n",
    "# display first 25 images in a 5x5 grid\n",
    "for index, file, age, gender in files.itertuples():\n",
    "    plt.subplot(5, 5, index + 1)\n",
    "    img = load_img(file)\n",
    "    img = np.array(img)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Age: \" + str(age) + \" Gender: \" + str(gender))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the features and normalize the pixels in each of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for image in df['image']:\n",
    "        img = load_img(image, color_mode = \"grayscale\")\n",
    "        img = img.resize((128, 128), 3)\n",
    "        img = np.array(img)\n",
    "        x.append(img)\n",
    "        \n",
    "x = np.array(x)\n",
    "x = x.reshape(len(x), 128, 128, 1)\n",
    "x = x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gender = np.array(df['gender'])\n",
    "y_age = np.array(df['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map this model so it can process both age and gender at the same time\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size = (3, 3), input_shape = input_shape, activation = 'relu'))\n",
    "# model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# model.add(Conv2D(64, kernel_size = (3, 3), input_shape = input_shape, activation = 'relu'))\n",
    "# model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# model.add(Conv2D(128, kernel_size = (3, 3), input_shape = input_shape, activation = 'relu'))\n",
    "# model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# model.add(Conv2D(256, kernel_size = (3, 3), input_shape = input_shape, activation = 'relu'))\n",
    "# model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(1, activation='relu'))\n",
    "\n",
    "# model.compile(optimizer = 'adam', loss = 'mae', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((128, 128, 1))\n",
    "\n",
    "#instead of building model the classical way, we can add to separate hidden layers which would check for both age and gender and then pass to individual output layers\n",
    "Conv2D_1 = Conv2D(32, kernel_size = (3, 3), strides = 1, padding = \"same\", activation = 'relu') (inputs)\n",
    "MaxPooling2D_1 = MaxPooling2D(pool_size = (2, 2)) (Conv2D_1)\n",
    "Conv2D_2 = Conv2D(64, kernel_size = (3, 3), strides = 1, padding = \"same\", activation = 'relu') (MaxPooling2D_1)\n",
    "MaxPooling2D_2 = MaxPooling2D(pool_size = (2, 2)) (Conv2D_2)\n",
    "Conv2D_3 = Conv2D(128, kernel_size = (3, 3), strides = 1, padding = \"same\", activation = 'relu') (MaxPooling2D_2)\n",
    "MaxPooling2D_3 = MaxPooling2D(pool_size = (2, 2)) (Conv2D_3)\n",
    "Conv2D_4 = Conv2D(256, kernel_size = (3, 3), strides = 1, padding = \"same\", activation = 'relu') (MaxPooling2D_3)\n",
    "MaxPooling2D_4 = MaxPooling2D(pool_size = (2, 2)) (Conv2D_4)\n",
    "\n",
    "Flatten = Flatten() (MaxPooling2D_4)\n",
    "\n",
    "Dense_1 = Dense(256, activation='relu') (Flatten)\n",
    "Dense_2 = Dense(256, activation='relu') (Flatten)\n",
    "\n",
    "Dropout_1 = Dropout(0.3) (Dense_1)\n",
    "Dropout_2 = Dropout(0.3) (Dense_2)\n",
    "\n",
    "Dense_output_1 = Dense(1, activation='sigmoid', name='gender_out') (Dropout_1)\n",
    "Dense_output_2 = Dense(1, activation='relu', name='age_out') (Dropout_2)\n",
    "\n",
    "model = Model(inputs = [inputs], outputs = [Dense_output_1, Dense_output_2])\n",
    "\n",
    "model.compile(loss=['binary_crossentropy', 'mae'], optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x = x, y = [y_gender, y_age], epochs = 20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['gender_out_accuracy']\n",
    "val_acc = history.history['val_gender_out_accuracy']\n",
    "epochs = range(len(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
