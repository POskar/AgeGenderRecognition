{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Age and Gender Prediction From Face Images Using Attentional Convolutional Network\n",
    "<img src=\"images/[1]Attentional Convolutional Network.png\"> <br>\n",
    "+\n",
    "<img src=\"images/[1]2.png\"> <br>\n",
    "Document is available at: https://arxiv.org/pdf/2010.03791.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to import used libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, pandas as pd, matplotlib.pyplot as plt, numpy as np, os\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helper.reference_1.ResidualAttentionNetwork import ResidualAttentionNetwork\n",
    "from helper.prepare_data import prepare_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we pick the dataset that we would like to use from:\n",
    "<br>1 - Age, gender, ethnicity CSV\n",
    "<br>2 - UTKFace\n",
    "<br>3 - Fairface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data from each dataset so that we end up with normalized pixels and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x, y_age, y_gender, y_ethnicity, img_size \u001b[39m=\u001b[39m prepare_data(choice \u001b[39m=\u001b[39;49m choice)\n\u001b[0;32m      2\u001b[0m y_age\n",
      "File \u001b[1;32mc:\\Users\\pieni\\Documents\\GitHub\\AgeGenderRecognition\\helper\\prepare_data.py:74\u001b[0m, in \u001b[0;36mprepare_data\u001b[1;34m(choice)\u001b[0m\n\u001b[0;32m      3\u001b[0m from PIL import Image, ImageOps\n\u001b[0;32m      5\u001b[0m def prepare_data(choice):\n\u001b[0;32m      6\u001b[0m     match choice:\n\u001b[0;32m      7\u001b[0m         case 1:\n\u001b[0;32m      8\u001b[0m             df = pd.read_csv(os.getcwd() + \"//datasets//age_gender.csv\")\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m             # image size originally is 48\n\u001b[0;32m     11\u001b[0m             img_size = 48\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m             # First split each pixel value and convert to float, only then we can normalize values of pixels from 0 - 255 to 0 - 1:\n\u001b[0;32m     14\u001b[0m             df['pixels'] = df['pixels'].apply(lambda x: np.array(x.split(), dtype = \"float32\"))\n\u001b[0;32m     15\u001b[0m             df['pixels'] = df['pixels'].apply(lambda x: x / 255)\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m             x = np.array(df['pixels'].tolist())\n\u001b[0;32m     18\u001b[0m             # x.shape[0] = 23705, those are number of entries in db file, last argument is 1 if greyscale, 3 if rgb images\n\u001b[0;32m     19\u001b[0m             x = x.reshape(x.shape[0], img_size, img_size, 1)\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m             x = np.array(x)\n\u001b[0;32m     22\u001b[0m             y_age = np.array(df['age'])\n\u001b[0;32m     23\u001b[0m             y_ethnicity = np.array(df['ethnicity'])\n\u001b[0;32m     24\u001b[0m             y_age = np.array(df['gender'])\n\u001b[0;32m     25\u001b[0m             return x, y_age, y_age, y_ethnicity, img_size\n\u001b[0;32m     26\u001b[0m         case 2:\n\u001b[0;32m     27\u001b[0m             directory = os.getcwd() + '//datasets//UTKFace//'\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m             # image size originally is 200\n\u001b[0;32m     30\u001b[0m             img_size = 64\n\u001b[0;32m     31\u001b[0m             \n\u001b[0;32m     32\u001b[0m             # lists for storing labels\n\u001b[0;32m     33\u001b[0m             image_paths = []\n\u001b[0;32m     34\u001b[0m             age_labels = []\n\u001b[0;32m     35\u001b[0m             gender_labels = []\n\u001b[0;32m     36\u001b[0m \n\u001b[0;32m     37\u001b[0m             for filename in os.listdir(directory):\n\u001b[0;32m     38\u001b[0m                 image_path = os.path.join(directory, filename)\n\u001b[0;32m     39\u001b[0m                 temp = filename.split('_')\n\u001b[0;32m     40\u001b[0m                 age = int(temp[0])\n\u001b[0;32m     41\u001b[0m                 gender = int(temp[1])\n\u001b[0;32m     42\u001b[0m                 image_paths.append(image_path)\n\u001b[0;32m     43\u001b[0m                 age_labels.append(age)\n\u001b[0;32m     44\u001b[0m                 gender_labels.append(gender)\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m             df = pd.DataFrame()\n\u001b[0;32m     47\u001b[0m             df['image'], df['age'], df['gender'] = image_paths, age_labels, gender_labels\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m             x = []\n\u001b[0;32m     50\u001b[0m             for image in df['image']:\n\u001b[0;32m     51\u001b[0m                     # img = load_img(image, color_mode = \"grayscale\")\n\u001b[0;32m     52\u001b[0m                     img = load_img(image, grayscale=False)\n\u001b[0;32m     53\u001b[0m                     # img = img.resize((img_size, img_size), 3)\n\u001b[0;32m     54\u001b[0m                     img = img.resize((img_size, img_size), Image.ANTIALIAS)\n\u001b[0;32m     55\u001b[0m                     img = np.array(img)\n\u001b[0;32m     56\u001b[0m                     x.append(img)\n\u001b[0;32m     57\u001b[0m \n\u001b[0;32m     58\u001b[0m             x = np.array(x)\n\u001b[0;32m     59\u001b[0m             x = x.reshape(len(x), img_size, img_size, 3)\n\u001b[0;32m     60\u001b[0m             x = x/255.0\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m             y_age = np.array(df['age'])\n\u001b[0;32m     63\u001b[0m             y_gender = np.array(df['gender'])\n\u001b[0;32m     64\u001b[0m             if 'ethnicity' in df.columns:\n\u001b[0;32m     65\u001b[0m                 y_ethnicity = np.array(df['ethnicity'])\n\u001b[0;32m     66\u001b[0m             else:\n\u001b[0;32m     67\u001b[0m                 y_ethnicity = np.empty(0)\n\u001b[0;32m     68\u001b[0m             return x, y_age, y_gender, y_ethnicity, img_size\n\u001b[0;32m     69\u001b[0m         case 3:\n\u001b[0;32m     70\u001b[0m             directory = os.getcwd() + '//datasets//Fairface//val'\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m             # image size originally is 224\n\u001b[0;32m     73\u001b[0m             img_size = 224\n\u001b[1;32m---> 74\u001b[0m             \n\u001b[0;32m     75\u001b[0m             x = []\n\u001b[0;32m     76\u001b[0m \n\u001b[0;32m     77\u001b[0m             for filename in os.listdir(directory):\n\u001b[0;32m     78\u001b[0m                 image_path = os.path.join(directory, filename)\n\u001b[0;32m     79\u001b[0m                 img = load_img(image_path, color_mode = \"grayscale\")\n\u001b[0;32m     80\u001b[0m                 img = img.resize((img_size, img_size), 3)\n\u001b[0;32m     81\u001b[0m                 img = np.array(img)\n\u001b[0;32m     82\u001b[0m                 x.append(img)\n\u001b[0;32m     83\u001b[0m \n\u001b[0;32m     84\u001b[0m             x = np.array(x)\n\u001b[0;32m     85\u001b[0m             x = x.reshape(len(x), img_size, img_size, 1)\n\u001b[0;32m     86\u001b[0m             x = x/255.0\n\u001b[0;32m     87\u001b[0m \n\u001b[0;32m     88\u001b[0m             df = pd.read_csv(os.getcwd() + \"//datasets//Fairface//fairface_label_val.csv\")\n\u001b[0;32m     89\u001b[0m             y_age = []\n\u001b[0;32m     90\u001b[0m             y_gender = []\n\u001b[0;32m     91\u001b[0m             y_ethnicity = [] \n\u001b[0;32m     92\u001b[0m \n\u001b[0;32m     93\u001b[0m             for entry in np.array(df['age']):\n\u001b[0;32m     94\u001b[0m                 if entry == '0-2':\n\u001b[0;32m     95\u001b[0m                     y_age.append(0)\n\u001b[0;32m     96\u001b[0m                 elif entry == '3-9':\n\u001b[0;32m     97\u001b[0m                     y_age.append(1)\n\u001b[0;32m     98\u001b[0m                 elif entry == '10-19':\n\u001b[0;32m     99\u001b[0m                     y_age.append(2)\n\u001b[0;32m    100\u001b[0m                 elif entry == '20-29':\n\u001b[0;32m    101\u001b[0m                     y_age.append(3)\n\u001b[0;32m    102\u001b[0m                 elif entry == '30-39':\n\u001b[0;32m    103\u001b[0m                     y_age.append(4)\n\u001b[0;32m    104\u001b[0m                 elif entry == '40-49':\n\u001b[0;32m    105\u001b[0m                     y_age.append(5)\n\u001b[0;32m    106\u001b[0m                 elif entry == '50-59':\n\u001b[0;32m    107\u001b[0m                     y_age.append(6)\n\u001b[0;32m    108\u001b[0m                 elif entry == '60-69':\n\u001b[0;32m    109\u001b[0m                     y_age.append(7)\n\u001b[0;32m    110\u001b[0m                 elif entry == 'more than 70':\n\u001b[0;32m    111\u001b[0m                     y_age.append(8)\n\u001b[0;32m    112\u001b[0m \n\u001b[0;32m    113\u001b[0m             for entry in np.array(df['gender']):\n\u001b[0;32m    114\u001b[0m                 if entry == \"Male\":\n\u001b[0;32m    115\u001b[0m                     y_gender.append(0)\n\u001b[0;32m    116\u001b[0m                 elif entry == \"Female\":\n\u001b[0;32m    117\u001b[0m                     y_gender.append(1)\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m             for entry in np.array(df['race']):\n\u001b[0;32m    120\u001b[0m                 if entry == \"White\":\n\u001b[0;32m    121\u001b[0m                     y_ethnicity.append(0)\n\u001b[0;32m    122\u001b[0m                 elif entry == \"Black\":\n\u001b[0;32m    123\u001b[0m                     y_ethnicity.append(1)\n\u001b[0;32m    124\u001b[0m                 elif entry == \"Latino_Hispanic\":\n\u001b[0;32m    125\u001b[0m                     y_ethnicity.append(2)\n\u001b[0;32m    126\u001b[0m                 elif entry == \"East\":\n\u001b[0;32m    127\u001b[0m                     y_ethnicity.append(3)\n\u001b[0;32m    128\u001b[0m                 elif entry == \"Southeast Asian\":\n\u001b[0;32m    129\u001b[0m                     y_ethnicity.append(4)\n\u001b[0;32m    130\u001b[0m                 elif entry == \"Indian\":\n\u001b[0;32m    131\u001b[0m                     y_ethnicity.append(5)\n\u001b[0;32m    132\u001b[0m                 elif entry == \"Middle Eastern\":\n\u001b[0;32m    133\u001b[0m                     y_ethnicity.append(6)\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m             y_age = np.array(y_age)\n\u001b[0;32m    136\u001b[0m             y_gender = np.array(y_gender)\n\u001b[0;32m    137\u001b[0m             y_ethnicity = np.array(y_ethnicity)\n\u001b[0;32m    138\u001b[0m \n\u001b[0;32m    139\u001b[0m             return x, y_age, y_gender, y_ethnicity, img_size\n\u001b[0;32m    140\u001b[0m         case _:\n\u001b[0;32m    141\u001b[0m             return 0,0,0,0,0\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x, y_age, y_gender, y_ethnicity, img_size = prepare_data(choice = choice)\n",
    "y_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display some exemplary images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the whole grid of images\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# display first 25 images in a 5x5 grid\n",
    "for i in range(0, 25):\n",
    "    plt.subplot(5, 5, (i % 25) + 1)\n",
    "    plt.grid(False)\n",
    "    #disable x and y axis description\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(x[i].reshape(img_size, img_size), cmap='gray')\n",
    "    # A = age, G = gender, E = ethnicity\n",
    "    plt.xlabel(\"A: \"+ str(y_age[i]) + \" G: \" + str(y_gender[i]) + (\" E: \" + str(y_ethnicity[i]) if y_ethnicity.size > 0 else \"\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://github.com/deontaepharr/Residual-Attention-Network\n",
    "# model = ResidualAttentionNetwork((img_size, img_size, 1), 1, activation='sigmoid').build_model()\n",
    "# model.compile(optimizer = Adam(lr=0.0001), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "# model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file = os.getcwd() + '//images//[1]_model.png', show_shapes = True, show_dtype = False, show_layer_names = False, rankdir = 'TB', expand_nested = False, dpi = 96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we might use validation_split or we can divide sets as before which allows for reproducibility, but 3rd dataset is a bit messy in this matter\n",
    "# seed = 100\n",
    "# x_train_age, x_test_age, y_train_age, y_test_age = train_test_split(x, y_age, test_size = 0.2, random_state = seed)\n",
    "# x_train_ethnicity, x_test_ethnicity, y_train_ethnicity, y_test_ethnicity = train_test_split(x, y_ethnicity, test_size = 0.2, random_state = seed)\n",
    "\n",
    "history = model.fit(x, y_age , epochs = 10, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_acc = np.array(history.history['age_out_accuracy'])\n",
    "age_val_acc = np.array(history.history['val_age_out_accuracy'])\n",
    "epochs = range(len(age_acc))\n",
    "\n",
    "plt.plot(epochs, age_acc, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, age_val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Age Accuracy Graph')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_acc = np.array(history.history['gender_out_accuracy'])\n",
    "gender_val_acc = np.array(history.history['val_gender_out_accuracy'])\n",
    "epochs = range(len(gender_acc))\n",
    "\n",
    "plt.plot(epochs, gender_acc, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, gender_val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Gender Accuracy Graph')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
